# Lecture 1 -  Introduction to Machine Learning:

1. (7min): https://www.youtube.com/watch?v=ukzFI9rgwfU
2. (7min): AI vs Ms vs DL vs Data Science, nice discussion: https://www.youtube.com/watch?v=k2P_pHQDlp0
3. (~60min): My favorite youtube lecturer Mathematical on Machine Learning: https://www.youtube.com/watch?v=yDLKJtOVx5c&list=PLD0F06AA0D2E8FFBA

## Blogs and Text:
https://www.technologyreview.com/2018/11/17/103781/what-is-machine-learning-we-drew-you-another-flowchart/
One of the best blog entries on Introduction to Machine Learning that I have read so far: https://vas3k.com/blog/machine_learning/

# Information on statistical evaluation metrics (recall, sensitivity, RoC, confusion matrix):

1. (35min) Confusion Matrix: https://www.youtube.com/watch?v=8Oog7TXHvFY
2. Blogplost on confusion Matrix: https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/
3. RoC curves and AuC explained (Generally important): https://www.youtube.com/watch?v=OAl6eAyP-yo
4. (7 min): Accuracy, Recall and Precision https://www.youtube.com/watch?v=VPZiJGNX4_s
5. (10min) Sensitivity and Specificity: https://www.youtube.com/watch?v=vP06aMoz4v8
6. Blog Post on Accuracy, Precision and Recall: https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/
7. Pretty amazing blog post on ML evaluation measures (must read): https://classeval.wordpress.com/introduction/basic-evaluation-measures/


# Lecture 2 - Probabilities and Naive-Bayes:

## Videos:
1. (15min) Amazing video von Bayes Theorem: https://www.youtube.com/watch?v=HZGCoVF3YvM
2. (15min) another amazing tutorial explaining concepts in probability: https://www.youtube.com/watch?v=SrEmzdOT65s
3. (7min) https://www.youtube.com/watch?v=Zt83JnjD8zg
4. (30min) Super cool video on how to use Naive Bayes for text classification)

## Blogs: 
1. https://www.investopedia.com/terms/b/bayes-theorem.asp
2. Great blog: https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/
3. Another great blog: https://machinelearningmastery.com/bayes-theorem-for-machine-learning/

# Lecture 3 - Decision Trees:

## Videos:
1. (10min) https://www.youtube.com/watch?v=eKD5gxPPeY0
2. (17min) https://www.youtube.com/watch?v=7VeUPuFGJHk
3. (~60min) Amazing Lectures series with short videos on Decision Trees: https://www.youtube.com/watch?v=Pz6xX6rK5M4&list=PLBv09BD7ez_4_UoYeGrzvqveIR_USBEKD
4. 60min: My favorite youtube lecturer has this series: https://www.youtube.com/watch?v=p17C9q2M00Q&list=PLScpSunNAuBY8E5O2s_61jToIHuYKp_c7

# Lecture 4 - Measuring Distances

# Blogs:
1. 4 Distance Measures for Machine Learning: https://machinelearningmastery.com/distance-measures-for-machine-learning/
2. Short read: 3 Common Techniques of Similarity and Distance Measure in Machine Learning https://machinelearningknowledge.ai/3-common-techniques-similarity-distance-measure-machine-learning/
3. Mathematical description of Vector Norms: http://fourier.eng.hmc.edu/e161/lectures/algebra/node11.html
4. Great Read: Vector Norms and Inequalities with Python https://aaronschlegel.me/vector-norms-inequalities-python.html
5. Another Great Read: Matrix Norms and Inequalities with Python https://aaronschlegel.me/matrix-norms-inequalities-python.html
6. Beautiful description of Mahalaobis distances and its importance: https://www.machinelearningplus.com/statistics/mahalanobis-distance/
7. KL-divergence explained: https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained
8. Another example of KL-divergence: https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence-2b382ca2b2a8
9. Last: Importance of Distance Metrics in Machine Learning Modelling https://towardsdatascience.com/importance-of-distance-metrics-in-machine-learning-modelling-e51395ffe60d

## Videos:
1. (7min): Jupyter Notebook video on L0 and L1 distance measures: https://www.youtube.com/watch?v=-3Uq_FZkzpc
2. (7min): Visualizing norms as unit circles: https://www.youtube.com/watch?v=SXEYIGqXSxk
3. (6min): Short video on vector norms: https://www.youtube.com/watch?v=5fN2J8wYnfw
4. (10min): Mahalaobis Distance (weighted norms): https://www.youtube.com/watch?v=3IdvoI8O9hU
5. (42min): Classical Black-Board lecture on Norms (I do like those ...): https://www.youtube.com/watch?v=NcPUI7aPFhA
6. (13min): Levensthein Edit Distane: https://www.youtube.com/watch?v=Xxx0b7djCrs
7. (10min): KL-divergence: https://www.youtube.com/watch?v=LJwtEaP2xK
8. (12min): A Short Introduction to Entropy, Cross-Entropy and KL-Divergence - https://www.youtube.com/watch?v=ErfnhcEV1O8

# Lecture 5 - K-NN

## Videos:
1. (10min) Mathematical Monk (must watch!): https://www.youtube.com/watch?v=4ObVzTuFivY
2. (10min) Victor Lavrenk (another must watch!): https://www.youtube.com/watch?v=k_7gMp5wh5A
3. (50min) If you like the full blackboard lectures: https://www.youtube.com/watch?v=09mb78oiPkA
4. (10min) Handwritten example of boundaries in KNN: https://www.youtube.com/watch?v=JtBtVNtTXRQ

## Blogs
1. KNN in Python (don't use this code, we implement it from scratch): https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/
2. Wikipedia article is great: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm
3. Beautiful Blog entry on KNN by Kevin Zakka: https://kevinzakka.github.io/2016/07/13/k-nearest-neighbor/
4. Free book to download and read (for indepth understanding): ntroduction to Statistical Learning with Applications in R, Chapters 2 and 3 - http://faculty.marshall.usc.edu/gareth-james/
5. A Detailed Introduction to K-Nearest Neighbor (KNN) Algorithm: https://saravananthirumuruganathan.wordpress.com/2010/05/17/a-detailed-introduction-to-k-nearest-neighbor-knn-algorithm/



# Lecture 6 - Linear and Polyomial Regression

## Videos
1. (~60 min) Video series on linear regression: https://www.youtube.com/watch?v=rVviNyIR-fI
2. (~60 min) Andrew Ng's full series on regression models: https://www.youtube.com/watch?v=kHwlB_j7Hkc&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&index=4
His series Nr. 3 is refresher on Linear Algebra, but then Lecture Nr. 4 is on linear regression multiple variables: https://www.youtube.com/watch?v=Q4GNLhRtZNc&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&index=18
3. (4min) Super short (but great) video on Polynomial Regression: https://www.youtube.com/watch?v=nGcMl03LPC0
4. (9min) Great video om Polynomial Regression: https://www.youtube.com/watch?v=QptI-vDle8Y
5. (13min) quite mathematical (but you'll need those equations) of linear regression: https://www.youtube.com/watch?v=K_EH2abOp00

# Blogs
1. Wikiedpia entry on Linear Regresion is indeed pretty good: https://en.wikipedia.org/wiki/Linear_regression
2. Wikipedia entry on Polynomial regression is indeed pretty good: https://en.wikipedia.org/wiki/Polynomial_regression
3. Regression is very common lecture topic in many different classes, not just ML. I found this very long and comprehensive lecture notes which basically comprise everything you need to know: https://stat.ethz.ch/education/semesters/ss2012/regression/RegressionEnglish.pdf

# Lecture 7 - Perceptron and Linear Discriminat Analysis

[Some history on the importance of perceptrons] (https://news.cornell.edu/stories/2019/09/professors-perceptron-paved-way-ai-60-years-too-soon)

## Videos
1. (13min)[Really nice Video Introduction](https://www.youtube.com/watch?v=4Gac5I64LM4)
2. (9min)[Another great introduction video](https://www.youtube.com/watch?v=5g0TPrxKK6o)
3. (45min) [Beautiful, quite easy series on perceptrons](https://www.youtube.com/watch?v=jbluHIgBmBo)

## Readings 
1. Very Comprehensive, but mathy overview of Perceptron and relations to other ML-algorithms:
https://www.pearsonhighered.com/assets/samplechapter/0/1/3/1/0131471392.pdf
2. [A nice (not super mathy) blog on perceptrons (I recommend!!!)[https://towardsdatascience.com/perceptron-learning-algorithm-d5db0deab975]

# Lecture 8 - Logistic Regression

## Video:
1. (9min) [Introduction to Regression](https://www.youtube.com/watch?v=yIYKR4sgzI8), [Part 2](https://www.youtube.com/watch?v=BfKanl1aSG0)
2. (10min) [Andrew Ng's Lecture Series on Logistic Regression](https://www.youtube.com/watch?v=-la3q9d7AKQ)
3. (15min) [Mathematic Monk AWESOME video on logistic regression](https://www.youtube.com/watch?v=-Z2a_mzl9LM)

## Blogs:
1. [Detailed Overview, but great](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc)
2. [Just a great introduction to logistic regression](https://christophm.github.io/interpretable-ml-book/logistic.html)
3. [Wikipedia is very comprehensive and maybe too much, but it's still pretty helpful](https://en.wikipedia.org/wiki/Logistic_regression)

# Lecture 9 - Gradient Descent for Optimizing the Loss Function

## Recap on Partial Derivatives and the Gradient of multi-dimensional functions
1. [What is a partical derivative ?](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/introduction-to-partial-derivatives) and then [What is the Gradient](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/the-gradient)
2. [A pretty nice sub-wiki which really covers everything you need to know](https://calculus.subwiki.org/wiki/Gradient_vector)
3. [This is deep learning blog, but everything said on Gradients is generally true and I really like this blog entry](https://towardsdatascience.com/step-by-step-the-math-behind-neural-networks-490dc1f3cfd9)
4. A bunch of examples where gradients are caculated: https://www.varsitytutors.com/linear_algebra-help/the-gradient
5. Linear Algebra and the Gradient (Deriving gradients with matrices, super important for ML): https://www.varsitytutors.com/linear_algebra-help/the-gradient
6. Understanding the math behind Gradient Descent: https://towardsdatascience.com/understanding-the-mathematics-behind-gradient-descent-dde5dc9be06e

## Understanding Gradient Descent Algorithm
1. (22min)[Step-by-Step introduction](https://www.youtube.com/watch?v=sDv4f4s2SB8)
2. Gradient Descent - THE MATH YOU SHOULD KNOW: https://www.youtube.com/watch?v=-p1ldISb90Q


### Book/ more scientific papers and reads:
1. Great (no, amazing) book on convex optimization (read chapter 1 - Introduction on a broad overview of Optimization not limited to Gradient Descent): https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf 
A few notes on this book: Every applied math/computer scientist grad student should have read this book (or at least large parts of it). (Convex) Optimization is such an important field which you'll find every where. Obviously, we can't teach it in this class, but I recommend you this book a lot!
2. An overview of gradient descent optimizationalgorithms (quite scientific but gives comprehensive overview): https://arxiv.org/pdf/1609.04747.pdf

# Lecture 9.2 Part - Regularization

## Occam’s Razor (preferring simpler models):
1. [Nice, basic video (without any math)] (https://www.youtube.com/watch?v=M5WDdvkFaDg)
2. [A bit more mathy video on Occam Razor for ML](https://www.youtube.com/watch?v=Q_AclBHCaUo)

### Blogs:
1. Intuition of Regularization (blog): https://towardsdatascience.com/intuitions-on-l1-and-l2-regularisation-235f2db4c261
2. Great read from Berkley with amazing derivations: http://courses.ieor.berkeley.edu/ieor165/lecture_notes/ieor165_lec8.pdf
3. A concise but pretty clear read on how prior probability and regularization terms are connected: https://rohanvarma.me/Regularization/

### Videos
1. Andrew NG series on Regularization [Part1: The Problem Of Overfitting](https://www.youtube.com/watch?v=u73PU6Qwl1I), [Part 2: Lost Function]( https://www.youtube.com/watch?v=KvtGD37Rm5I ), [Part 3: Regularized Linear Regression] ( https://www.youtube.com/watch?v=qbvRdrd0yJ8 )
2. Lp regularization penalties; comparing L2 vs L1: https://www.youtube.com/watch?v=sO4ZirJh9ds
3. Josh Stormers regularization video: [Part 1](https://www.youtube.com/watch?v=Q81RR3yKn30), [Part 2](https://www.youtube.com/watch?v=NGf0voTMlcs)

# Lecture 10 - Support Vector Machines

## Blogs and Reading
1. [Great introduction by a stanford ](https://nlp.stanford.edu/IR-book/html/htmledition/support-vector-machines-the-linearly-separable-case-1.html)
2. [Support Vector Machine — Simply Explained](https://towardsdatascience.com/support-vector-machine-simply-explained-fee28eba5496
3. [Blog: Another quick read](https://medium.com/towards-artificial-intelligence/support-vector-machine-svm-a-visual-simple-explanation-part-1-a7efa96444f2)
4. [Lecture Slides: Just great lecture slides that I've enjoyed on SVM](https://www.cs.cmu.edu/~tom/10701_sp11/slides/Kernels_SVM2_04_12_2011-ann.pdf)
5. [Andre Ng's lecture notes: These are one of the best. Read through those if you really want to dig into them](http://cs229.stanford.edu/notes/cs229-notes3.pdf)

## Video Material
1. [Andrew Ng's Video series on SVM is amazing:](https://www.youtube.com/watch?v=hCOIMkcsm_g&list=PLNeKWBMsAzboNdqcm4YY9x7Z2s9n9q_Tb)
2. [(20min) Statquest is always a great resource](https://www.youtube.com/watch?v=efR1C6CvhmE)
3. [(10min) The math you should know](https://www.youtube.com/watch?v=05VABNfa1ds)
4. [80min: If you wanna see a black-board lecture by Andrew Ng on SVM](https://www.youtube.com/watch?v=lDwow4aOrtg)


# Lecture 11 - Principial Component Analaysis

## Curse-of-dimensionality
1. [(3min) All you need to know](https://www.youtube.com/watch?v=QZ0DtNFdDko)
2. [(40min) If you really want to understand it, watch this lecture](https://www.youtube.com/watch?v=BbYV8UfMJSA)
3. [BLOG: Absolutely beautiful explanation! Read this, super rewarding](https://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/)

# Math Primer on SVD
1. [Super nice series on SVD](https://www.youtube.com/watch?v=gXbThCXjZFM&list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv)
2. [Blog Entry](https://andrew.gibiansky.com/blog/mathematics/cool-linear-algebra-singular-value-decomposition/)
3. [2D-visualizaton tool for SVD](https://lambein.xyz/blog/2018/12/20/svd-visualization.html)

## Videos on PCA
1. [I love Victor Lavrenkos video. To me this is a must watch!!!](http://bit.ly/PCA-alg)
2. [(20min) StatQuest makes great videos](https://www.youtube.com/watch?v=_UVHneBUBW0)
https://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/

## Blogs on PCA
1. [A One-Stop Shop for Principal Component Analysis](https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c)
2. [Absolutely stunning interactive visualization of PCA in 2D and 3D](https://setosa.io/ev/principal-component-analysis/)
3. [Blog: I've taken much inspirtation for my lecture from here](https://www.visiondummy.com/2014/05/feature-extraction-using-pca/)

## Practial stuff to know when doing dimensionality reduction
1. [MUST READ: About Feature Scaling and Normalization](https://sebastianraschka.com/Articles/2014_about_feature_scaling.html)
2. [Understanding the Difference Between Normalization vs. Standardization](https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/)

## Eigenfaces (the standard example for PCA)
1. [(6min) Nice visualizations](https://www.youtube.com/watch?v=J0arU2PAMls)
2. [Small tutorial on Eigenfaces](http://blog.manfredas.com/eigenfaces-tutorial/)
3. [Another great tutorial for eigenfaces](https://bastian.rieck.me/blog/posts/2015/eigenfaces_reconstruction/)

# Lecture 12 - K-Means Clustering

## Videos
1. (13min and 14min) Mathematical Monk! Create Video Series, MUST WATCH [Part 1](https://www.youtube.com/watch?v=0MQEt10e4NM&list=PLD0F06AA0D2E8FFBA&index=115&t=0s),[Part 2](https://www.youtube.com/watch?v=4shfFAArxSc&list=PLD0F06AA0D2E8FFBA&index=115)
2. (8min)[ Short video by victor Lavrenko](https://www.youtube.com/watch?v=_aWzGGNrcic)
3. Andrew NG's Video series Unsupervised Learning (clustering) [Part 1 (3min) ](https://www.youtube.com/watch?v=Ev8YbxPu_bQ&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&index=76), [Part 2](https://www.youtube.com/watch?v=hDmNF9JG3lo&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&index=77), other parts just follow up
4. Alexander Ihler's great clustering series (MUST WATCH) [Clustering](https://www.youtube.com/watch?v=6R16reLVl3I&list=PLaXDtXvwY-oDvedS3f4HW0b4KxqpJ_imw&index=32&t=0s), [Hierarchical Agglomerative Clustering (wasn't discussed in class)](https://www.youtube.com/watch?v=OcoE7JlbXvY&list=PLaXDtXvwY-oDvedS3f4HW0b4KxqpJ_imw&index=32), [K-Means clustering](https://www.youtube.com/watch?v=mfqmoUN-Cuw&list=PLaXDtXvwY-oDvedS3f4HW0b4KxqpJ_imw&index=33), 
5. (3min) [Soft clustering, super concise](https://www.youtube.com/watch?v=_gTagx25MQs), [GMM](https://www.youtube.com/watch?v=qMTuMa86NzU&list=PLaXDtXvwY-oDvedS3f4HW0b4KxqpJ_imw&index=34)
6. (13min) [A standford lecture on K-Means with a small theoretical discussion on initialization and complexity at the end](https://www.youtube.com/watch?v=RD0nNK51Fp8)


## Blogs and Reading
1. [Understanding K-means Clustering in Machine Learning](https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1)
2. [The Most Comprehensive Guide to K-Means Clustering You’ll Ever Need](https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-k-means-clustering/)
3. [K-means with sci-kit learn (not to be used since you have to implement yourself, but still great resource](https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html)
4. [K-means clustering with pesudo-code. Please refer to this one](https://stanford.edu/~cpiech/cs221/handouts/kmeans.html)

## Initialization methods
1. (8min)[K-Means initiliaztion with K++ explained concisce](https://www.youtube.com/watch?v=HatwtJSsj5Q)
2. (10min)[Coursera Video on K++ initialization, great and calm resource. Watch it if you want to understand it in detail](https://www.coursera.org/lecture/ml-clustering-and-retrieval/smart-initialization-via-k-means-T9ZaG)
3. [The original paper on K-means++ on good initialization (over 5000 citations)](http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf)
4. [Blog entry on K-means++ with Python example - feel free to use this for your implementation](http://www.geeksforgeeks.org/ml-k-means-algorithm/)


# Lecture 13 - Gaussian Mixture Models and Expectation Maximization

Gaussian Micture Models are a more "mathematical/statistical" augmentation of the soft K-means clustering algorithm. They can become pretty mathematical (as you've probably seen from my lecture videos. One of the biggest things to understand is the "Expectation Maximization" algorithm. Once derived and written down in formulars, there's really not so much to do for you, but I really urge you to try understanding what is the theory behind it.

# Videos
1. (12min)[Beautiful video, not really going in to the maths. Watch this first!!!](https://www.youtube.com/watch?v=DODphRRL79c)
2. (14min)[Mathmatical Monk's video are always great](https://www.youtube.com/watch?v=Rkl30Fr2S38)
3. [Amazing lecture series on Mixture models and great explanation of the EM-Algorithm by Victor Lavrenko. PLEASE watch](https://www.youtube.com/watch?v=REypj2sy_5U&list=PLBv09BD7ez_4e9LtmK626Evn1ion6ynrt) 
4. [Great, short, concise introduction to GMM](https://www.youtube.com/watch?v=EWd1xRkyEog)

# Blogs
1. [Great blog entry on GMM (MUST READ)](https://towardsdatascience.com/gaussian-mixture-models-explained-6986aaf5a95)
2. [A bite more mathy, but more comprehensive blog (MUST READ)](https://medium.com/@jonathan_hui/machine-learning-expectation-maximization-algorithm-em-2e954cb76959)
3. [Great Jupyter notebook example](https://github.com/ocontreras309/ML_Notebooks/blob/master/GMM_Implementation.ipynb)
4. [All the math you need](https://brilliant.org/wiki/gaussian-mixture-model/)
5. [Lecture notes on Mixture Models (only if you have time)](https://www.cs.ubc.ca/~murphyk/Teaching/CS340-Fall06/reading/mixtureModels.pdf)
6. [Distilling Gaussian Mixture Models](https://medium.com/sfu-cspmp/distilling-gaussian-mixture-models-701fa9546d9)
7. [GMM with Scikit learn, cannot be used for HW, but still nice to read](https://jakevdp.github.io/PythonDataScienceHandbook/05.12-gaussian-mixtures.html)
8. [GMM with Python code, you might be able to extract some parts for you HW](https://towardsdatascience.com/gaussian-mixture-models-gmm-6e95cbc38e6e)
9. [GMM with Pseudo-code - consice introduction](https://www.geeksforgeeks.org/gaussian-mixture-model/)

# Lecture 14 - Introduction to Neural Networks

There's a myriad of absolutely amazing lectures series on Deep Learning. I'm trying to include here a good mixture of videos, books and blog entries that cover the basics concepts that I deem necessary.

## Books
1. [MUST READ FOR EVERYONE: Deep Learning Book by Ian Goodfellow and Yoshua Bengio and Aaron Courville (This is the DL-bible)](https://www.deeplearningbook.org/)
2. [DeepLearning with PyTorch which covers all the basics and how to implement](https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf)

## Video Series
1. [(4 videos, 60mins)3Blue1Brown on DeepLearning is MUST watch](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
1. [(60min over 12 videos)Victor Lavrenkos are comprehensive and will give you everything you need!](https://www.youtube.com/watch?v=jZYz0EUPYBI&list=PLBv09BD7ez_4Bs9j3o8l_ZTjQZoN_3Oqs)
2. [(60min) Lex Fridman from MIT gives a stunning overview over Deep Learning and the Big Picture. This is a MUST watch for putting everything in concepts](https://www.youtube.com/watch?v=O5xeyoRL95U)
3. [Andrew Ngs introduction of Neural Networks is amazing. Please watch](https://www.youtube.com/watch?v=1ZhtwInuOD0&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&index=44&t=0s)

## Tutorials and Blogs

### Neural Nets
1. [(Blog) Using neural nets to recognize handwritten digits](http://neuralnetworksanddeeplearning.com/chap1.html)
2. [(Python Tutorial) How to Code a Neural Network with Backpropagation In Python (from scratch)](https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/)
3. [The Wikipedia article is actually quite informative](https://en.wikipedia.org/wiki/Feedforward_neural_network)
4. [(Blog) Deep Learning: Feedforward Neural Network](https://towardsdatascience.com/deep-learning-feedforward-neural-network-26a6705dbdc7)

### Activation Functions
1. [(Blog) 7 Types of Neural Network Activation Functions: How to Choose?](https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/)
2. [(Blog) Understanding Activation Functions in Neural Networks](https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0)
3. [(Blog) Everything you need to know about “Activation Functions” in Deep learning models](https://towardsdatascience.com/everything-you-need-to-know-about-activation-functions-in-deep-learning-models-84ba9f82c253)
4. [Amazing overview over different activation functions with animations](https://mlfromscratch.com/activation-functions-explained/#/)

### Backprogataion
1. [(Blog) A Step by Step Backpropagation Example](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)
2. [(Lectures Notes) How the backpropagation algorithm works](http://neuralnetworksanddeeplearning.com/chap2.html)
3. [Lecture Slides by Li-Fei Fei on Backprop](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture4.pdf)
4. [Lectures Notes by Cornell](https://www.cs.cornell.edu/courses/cs5740/2016sp/resources/backprop.pdf)
5. [(Blog) Neural networks and back-propagation explained in a simple way](https://medium.com/datathings/neural-networks-and-backpropagation-explained-in-a-simple-way-f540a3611f5e)

## Activation Functions
1. [(5min) Activation Functions Explained](https://www.youtube.com/watch?v=m0pIlLfpXWE)
2. [(10min) Activation functions again, different take[(https://www.youtube.com/watch?v=s-V7gKrsels)
3. [(15min) Why Activation Function and Which One Should You Use?](https://www.youtube.com/watch?v=MuYnv4_5ZcI)

## Backprogation
1. [(11min) Backpropagation explained | Part 1 - The intuition](https://www.youtube.com/watch?v=XE3krf3CQls)
2. [(15min) Brandon Rohrer is able to explain Backprogation USING daily life physics. Stunning example how you can make things simple](https://www.youtube.com/watch?v=6BMwisTZFr4)
3. [(11min) What's better than having Backprogagation explained from the inventor itself? See Geoffrey Hinton's take on it!](https://www.youtube.com/watch?v=LOc_y67AzCA)


## Fun Things
1. [Neural Networks learning Spirals if you cannot figure it out yourself](https://www.youtube.com/watch?v=i3ZnDRrmFjg)
2. [(6min) The Universal Approximation Theorem for neural networks](https://www.youtube.com/watch?v=Ijqkc7OLenI)
3. [Neural Network learning to play Snake](https://www.youtube.com/watch?v=zIkBYwdkuTk)
4. [(5min) Neural network racing cars around a track](https://www.youtube.com/watch?v=wL7tSgUpy8w)

# Lecture 15 - Convolutational Neural Networks

For Convolutational Networks I usually would refer to the same book as I did for Lecture 14 - Intro to NN. The Deep Learning book is maybe the best resource for finding information!

## Videos
1. [(9min)CNN explained simple for quick and dirty overview](https://www.youtube.com/watch?v=YRhxdVk_sIs)
2. [(32min) A friendly introduction to Convolutional Neural Networks and Image Recognition](https://www.youtube.com/watch?v=2-Ol7ZB0MmU)
3. [(60min) Brandon Rohrer: How convolutional neural networks work. This is REALLY in DEPTH. Amazing overview](https://www.youtube.com/watch?v=JB8T_zN7ZC0)

## Blogs and Reading Material
1. [(Great tutorial) An Intuitive Explanation of Convolutional Neural Networks](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/)
2. [(Blog) Understanding of Convolutional Neural Network (CNN) — Deep Learning](https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148)
3. [(Tutorial) Convolutional Neural Networks Tutorial in PyTorch](https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-in-pytorch/)
4. [(Tutorial) Build an Image Classification Model using Convolutional Neural Networks in PyTorch](https://www.analyticsvidhya.com/blog/2019/10/building-image-classification-models-cnn-pytorch/)
5. [(Tutorial) Li-Fei Feis course notes are amazing to read! Must read for undersstanding](https://cs231n.github.io/convolutional-networks/)
6. [Amazing tutorial that explains the channels really well. I couldn't go into that detail in my lecture](https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215)

## Convolultion Arthithmetics
1. [Convolution arithmetic tutorial](http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html)
2. [(Paper) A guide to convolution arithmetic for deeplearning](https://arxiv.org/pdf/1603.07285.pdf)
3. [(Tutorial) A Comprehensive Introduction to Different Types of Convolutions in Deep Learning](https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215)
4. [Understanding transposed convolutions](https://www.machinecurve.com/index.php/2019/09/29/understanding-transposed-convolutions/)

## How to calculate Input/Output sizes
1. [Quora 1](https://www.quora.com/How-can-I-calculate-the-size-of-output-of-convolutional-layer)
2. [Stackoverflow 1](https://stackoverflow.com/questions/53580088/calculate-the-output-size-in-convolution-layer)
3. [(Blog) How to calculate the number of parameters in the CNN?](https://medium.com/@iamvarman/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca)

## Feature Visualization

1. [How neural networks learn' - Part I: Feature Visualization](https://www.youtube.com/watch?time_continue=603&v=McgxRxi2Jqo&feature=emb_logo)
2. [(7min) Visualizing Convolutional Filters from a CNN](https://www.youtube.com/watch?v=cNBBNAxC8l4)
3. [(Visualization website) Visualizing Neural Networks with the Grand Tour](https://distill.pub/2020/grand-tour/)
4. [Computing Receptive Fields of Convolutional Neural Networks](https://distill.pub/2019/computing-receptive-fields/)
5. [Exploring Neural Networks with Activation Atlases](https://distill.pub/2019/activation-atlas/)
6. [Differentiable Image Parameterizations)[https://distill.pub/2018/differentiable-parameterizations/)
7. [Deconvolution and Checkerboard Artifacts](https://distill.pub/2016/deconv-checkerboard/)

# Lecture 16 - Reinforcement Learning
Reinforcment learning (RL) is a big part of Machine Learning and as itself such a huge field that we can only introduce the very basics of it in this course. Our lecture series focuses on defining the basic terminology that is required to understand what RL is about. We are discussing Q-Learning as example of off-policy learning that you'll have to implement in the HWs next to the simple Multi-Armed-Bandit Problem. Lastly, we show how we can combine Deep Learning and RL for so-called Deep Reinforcement Learning that for examples allows RL-Agents to play atari games based on only video input.

## RL - Book: This is the best resource you can get
Barto and Sutton's book on Reinforcement Learning is extremely well written and introduces you to RL like no other resource can do. For a proper understanding of the concepts discussed in 349 I recommend reading the following chapters:  Introduction and Tabular Methods (Chap. 1 to 6). The other parts are amazing, but go way beyond what we can do in the limited time we spend on RL in 349:

Link to book: https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf

## Full Lecture Series Online
One of the best full, fleged online courses on Reinforcement Learning is given by David Silver. The complete lecture slides and further material is found here: 

https://www.davidsilver.uk/teaching/

## Videos
There are many amazing videos on Reinforcement Learning. I particularly like the 2 videos linked here because they give an amazing introduction into the topic. Especially, Lex Fridman has a great way of teaching with talking about the bigger picture behind AI, Deep Learning and RL. He will defintely excite you about the topic and you will want to learn more about.

1. [(67min) Lex Fridman's video on Deep Reinforcement Learning are great](https://www.youtube.com/watch?v=zR11FLZ-O9M)
2. [Edureka 40min is a great resource which I found very instructive](https://www.youtube.com/watch?v=LzaWrmKL1Z4)

## General Reinforcement Learning
1. [Reinforcement Learning for self-study, several links:](https://github.com/hollygrimm/markov-decision-processes)
2. [Crystal Clear Reinforcement Learning: This tutorial/blog is very comprehensive and inclusive](https://towardsdatascience.com/crystal-clear-reinforcement-learning-7e6c1541365e)

## Markov-Decision-Process
1. [Reinforcement Learning : Markov-Decision Process (Part 1)](https://towardsdatascience.com/introduction-to-reinforcement-learning-markov-decision-process-44c533ebf8da)
2. [(13min) Concise introduction to Markov-Decision Processes](https://www.youtube.com/watch?v=U24wlvcxXBg)
3. [(2min) Super short introduction on MDP](https://www.youtube.com/watch?v=A12_bdqW6M8)
4. [(Blog) Great blog explaining Markov-Decision Processes](https://towardsdatascience.com/reinforcement-learning-demystified-markov-decision-processes-part-1-bf00dda41690)
5. [(Slides) The lecture slides by David Silver's course on MDP are great to scroll through](https://www.davidsilver.uk/wp-content/uploads/2020/03/MDP.pdf)

## Model-based vs Model-free Reinforcement Learning
1. [https://medium.com/@jonathan_hui/rl-model-based-reinforcement-learning-3c2b6f0aa323
](https://medium.com/@jonathan_hui/rl-model-based-reinforcement-learning-3c2b6f0aa323)
2. [(Discussion) Stackoverflow on Model-based vs Model-free](https://ai.stackexchange.com/questions/4456/whats-the-difference-between-model-free-and-model-based-reinforcement-learning)
3. [(Blog) From Model-Free to Model-Based Deep-RL (very instructive)](https://bairblog.github.io/2018/04/26/tdm/)

## On-Policy vs Off-Policy
1. [SARSA versus Q-learning – on-policy or off?](https://subscription.packtpub.com/book/data/9781789345803/1/ch01lvl1sec13/sarsa-versus-q-learning-on-policy-or-off)
2. [(22min video) Video from Sorbonne university](https://www.youtube.com/watch?v=hlhzvQnXdAA)

## Exploration vs Exploitation
1. [(10min) Exploration vs. Exploitation - Learning the Optimal Reinforcement Learning Policy](https://www.youtube.com/watch?v=mo96Nqlo1L8)
2. [(4min) Watch this for a super short recap if you feel you've already understood it somewhat](https://www.youtube.com/watch?v=yv8wJiQQ1rc)
3. [(Blog) On the Exploration vs. Exploitation dilemma](https://steemit.com/technology/@mor/machine-learning-series-part-5-exploration-vs-exploitation-dilemma-in-reinforcement-learning)
4. [(Tutorial) epsilon-Greedy Algorithm with code example](https://imaddabbura.github.io/post/epsilon-greedy-algorithm/)

## Multi Armed Bandit Problem
1. [(14min) recommended video on the MAB problem to understand the homework](https://www.youtube.com/watch?v=9LhNHK1ULxs)
2. [(35min) Not necessary for the lecture, but maybe interesting for a few: A MAB Framework for Recommendations at Netflix](https://www.youtube.com/watch?v=kY-BCNHd_dM)
3. [(15min) Another video on MAB (and Thompson sampling). Watch if the first video is not enough for you](https://www.youtube.com/watch?v=yQwJiFFIgjA)
4. [(Blog) The Multi-Armed Bandit Problem and Its Solutions](https://lilianweng.github.io/lil-log/2018/01/23/the-multi-armed-bandit-problem-and-its-solutions.html)
5. [(Blog) Simple introduction to MAB vs A/B Testing](https://vwo.com/blog/multi-armed-bandit-algorithm/)

## Q-Learning (Part of your Homework)
1. [(10min) Great, overview video](https://www.youtube.com/watch?v=qhRNvCVVJaA)
2. [(30min) A bit longer, but great video by Edureka](https://www.youtube.com/watch?v=DhdUlDIAG7Y)
3. [(Blog) Simple Reinforcement Learning: Q-learning](https://towardsdatascience.com/simple-reinforcement-learning-q-learning-fcddc4b6fe56)
4. [(Blog) A Beginners Guide to Q-Learning](https://towardsdatascience.com/a-beginners-guide-to-q-learning-c3e2a30a653c)
5. [(Tutorial) Step-by-Step into Q-Learning, similair slides used as in lecture](http://mnemstudio.org/path-finding-q-learning-tutorial.htm)

## Deep Reinforcment Learning
1. [A Beginner's Guide to Deep Reinforcement Learning](https://pathmind.com/wiki/deep-reinforcement-learning)
2. [A short video on Deep-Q Learning. Concise and gives a good introduction](https://www.youtube.com/watch?v=wrBUkpiRvCA)
3. [(6min) Replay Memory Explained - Experience for Deep Q-Network Training](https://www.youtube.com/watch?v=Bcuj2fTH4_4)
